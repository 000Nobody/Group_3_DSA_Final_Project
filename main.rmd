---
title: "main"
output: html_document
date: "2023-07-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(dplyr, ggplot2, glmnet, tidyverse, janitor, MASS, randomForest, muRL)
```

**Starting by importing and cleaning data**

```{r}
data <- read.csv("data/MA_Public_Schools_2017.csv", stringsAsFactors = T)

# Remove MCAS, AP columns
data_hs <- data[, -c(299:300, 98:295, 80:93, 16:25)]
# names(data_hs)

# Select only schools with high schoolers enrolled, clean column names
data_hs <- data_hs %>% 
  filter(
    (data_hs$X9_Enrollment !=0 | data_hs$X10_Enrollment !=0 | data_hs$X11_Enrollment !=0 | data_hs$X12_Enrollment !=0)
  ) %>% 
  dplyr::select(-c(
    Function, 
    State, 
    Address.1,
    Address.2, 
    Phone, 
    Fax, 
    Contact.Name, 
    School.Code, 
    SP_Enrollment, 
    TOTAL_Enrollment, 
    First.Language.Not.English, 
    English.Language.Learner, 
    Students.With.Disabilities, 
    High.Needs, 
    Economically.Disadvantaged, 
    Number.of.Students, 
    High.School.Graduates...., 
    Attending.Coll..Univ.....,
    Total.Expenditures,
    X..High.Needs)
  ) %>% 
  mutate(total_hs_enrollment = (
    X9_Enrollment + X10_Enrollment + X11_Enrollment + X12_Enrollment), 
    total_sat = (
      Average.SAT_Math + Average.SAT_Reading + Average.SAT_Writing) * (2/3)
  ) %>%
  mutate_if(is.character, as.factor) %>% 
  clean_names()

data_hs$sat_tests_taken <- data_hs$sat_tests_taken / data_hs$total_hs_enrollment
```
**Importing Crime Data**

```{r}
crime_data <- read.csv("data/MA_Crime.csv")
crime_data <- crime_data %>% clean_names() %>% rename(town = city) %>% mutate_if(is.numeric, as.character)

crime_data[2:12] <- lapply(crime_data[2:12], readr::parse_number)

crime_data_per_capita <- (crime_data[, 3:12] / crime_data[, 2]) * 100000
crime_data_per_capita <- cbind(crime_data[1:2], crime_data_per_capita)

data_hs <- merge(data_hs, crime_data_per_capita, by="town")[, -77]
```

**Splitting and organizing data**
```{r}
# Split data into training and testing 
picked = sample(seq_len(nrow(data_hs)), size = 220)
data_hs.training = data_hs[picked,]
data_hs.testing = data_hs[-picked,]

data_hs.testing <- data_hs.testing %>% drop_na()

#create new data frame with average total sat score, remove NAs
data_hs_sat <- data_hs.training %>% 
  dplyr::select(-c(
    average_sat_math, 
    average_sat_reading, 
    average_sat_writing,
    school_name,
    town,
    zip,
    grade,
    district_name,
    district_code,
    x_graduated,
    x_attending_college,
    x_private_two_year, 
    x_private_four_year, 
    x_public_two_year, 
    x_public_four_year, 
    x_ma_community_college, 
    x_ma_state_university, 
    x_u_mass
  )) %>% 
  remove_empty(which = c("cols", "rows")) %>%
  drop_na()

data_hs_gradrate <- data_hs.training %>% 
  filter(is.na(x_graduated) == F) %>% 
  dplyr::select(-c(
    school_name,
    town,
    zip,
    grade,
    district_name,
    district_code,
    x_attending_college,
    x_private_two_year, 
    x_private_four_year, 
    x_public_two_year, 
    x_public_four_year, 
    x_ma_community_college, 
    x_ma_state_university, 
    x_u_mass,
    x_dropped_out,
    x_still_in_school,
    x_non_grad_completers,
    x_ged
  )) %>% 
  remove_empty(which = c("cols", "rows")) %>%
  drop_na()

data_hs_college <- data_hs.training %>% 
  filter(is.na(x_attending_college) == F) %>% 
  dplyr::select(-c(
    school_name,
    town,
    zip,
    grade,
    district_name,
    district_code,
    x_private_two_year, 
    x_private_four_year, 
    x_public_two_year, 
    x_public_four_year, 
    x_ma_community_college, 
    x_ma_state_university, 
    x_u_mass)) %>% 
  drop_na()
  
# dim(data_hs_sat)
# dim(data_hs_gradrate)
# dim(data_hs_college)
```

**Basic EDA**

```{r}

# Graphing the distribution of dependent variables
data_hs_sat %>% ggplot(aes(x = total_sat)) + 
  geom_histogram(bins = 20, fill = "blue", col = "black") + 
  labs(title = "Average SAT Histogram", x = "Average SAT Score", y = "Frequency")

data_hs_gradrate %>% ggplot(aes(x = x_graduated)) + 
  geom_histogram(bins = 50, fill = "blue", col = "black") + 
  labs(title = "Graduation Rate Histogram")

data_hs_college %>% ggplot(aes(x = x_attending_college)) + 
  geom_histogram(bins = 30, fill = "blue", col = "black") + 
  labs(title = "College Attendance Rate Histogram")

indep_vars %>% ggplot(aes(x = salary_totals)) + 
  geom_histogram(bins = 30, fill = "blue", col = "black") + 
  labs(title = "Average Salary Histogram")

rbPal <- colorRampPalette(c('black','lightblue'))

sat_color <- rbPal(10)[as.numeric(cut(data_hs$total_sat,breaks = 10))]
zip.plot(data_hs, map.type="state", region="massachusetts", pch=16, col=sat_color, cex = data_hs$total_sat/700)

grad_color <- rbPal(10)[as.numeric(cut(data_hs$x_graduated,breaks = 10))]
zip.plot(data_hs, map.type="state", region="massachusetts", pch=16, col=sat_color, cex = data_hs$x_graduated/50)

coll_color <- rbPal(10)[as.numeric(cut(data_hs$x_attending_college,breaks = 10))]
zip.plot(data_hs, map.type="state", region="massachusetts", pch=16, col=sat_color, cex = data_hs$x_attending_college/50)
```


**LASSO Model for SAT**

```{r}
set.seed(1)

X.sat <- model.matrix(total_sat ~ ., data = data_hs_sat)
Y.sat <- data_hs_sat$total_sat

lasso_sat <- cv.glmnet(x = X.sat, y = Y.sat, alpha = .99, nfolds = 10)
plot(lasso_sat)

coef.sat <- coef(lasso_sat, s="lambda.1se")
coef.sat <- coef.sat[which(coef.sat !=0),]
var.sat <- rownames(as.matrix(coef.sat))[-1]

data_hs_sat.sub <- data_hs_sat[,c(var.sat, "total_sat")]

fit.sat <- lm(total_sat ~ ., data = data_hs_sat.sub)
model.sat <- stepAIC(fit.sat, direction = "both", trace = FALSE)
summary(model.sat)
plot(model.sat)

sat_test_result <- data.frame(predicted = predict(model.min.sat, data_hs.testing), actual = data_hs.testing$total_sat)
plot(x = sat_test_result$predicted, y = sat_test_result$actual)

residuals.lasso.sat <- predict(model.sat, data_hs.testing) - data_hs.testing$total_sat
mse.lasso.sat <- mean(residuals.lasso.sat^2)

sjPlot::plot_model(model.sat, type = 'pred', terms = c('x_economically_disadvantaged'))
sjPlot::plot_model(model.sat, type = 'pred', terms = c('x_females'))

```

**LASSO Model for Graduation Rate**
```{r}
set.seed(1)

X.grad <- model.matrix(x_graduated ~ ., data = data_hs_gradrate)
Y.grad <- data_hs_gradrate$x_graduated

lasso_grad <- cv.glmnet(x = X.grad, y = Y.grad, alpha = .99, nfolds = 10)
plot(lasso_grad)

coef.grad <- coef(lasso_grad, s="lambda.min")
coef.grad <- coef.grad[which(coef.grad !=0),]
var.grad <- rownames(as.matrix(coef.grad))[-1]

data_hs_gradrate.sub <- data_hs_gradrate[,c(var.grad, "x_graduated")]

fit.grad <- lm(x_graduated ~ ., data = data_hs_gradrate.sub)
model.grad <- stepAIC(fit.grad, direction = "both", trace = FALSE)
summary(model.grad)
plot(model.grad)

residuals.lasso.grad <- predict(model.grad, data_hs.testing) - data_hs.testing$x_graduated
mse.lasso.grad <- mean(residuals.lasso.grad^2)
```

**LASSO Model for College Attendance Rate**
```{r}
set.seed(1)

X.coll <- model.matrix(x_attending_college ~ ., data = data_hs_college)
Y.coll <- data_hs_college$x_attending_college

lasso_coll <- cv.glmnet(x = X.coll, y = Y.coll, alpha = .99, nfolds = 10)
plot(lasso_coll)

coef.coll <- coef(lasso_coll, s="lambda.min")
coef.coll <- coef.coll[which(coef.coll !=0),]
var.coll <- rownames(as.matrix(coef.coll))[-1]

data_hs_college.sub <- data_hs_college[,c(var.coll, "x_attending_college")]

fit.coll <- lm(x_attending_college ~ ., data = data_hs_college.sub)
model.coll <- stepAIC(fit.coll, direction = "both", trace = FALSE)
summary(model.coll)
plot(model.coll)

residuals.lasso.coll <- predict(model.coll, data_hs.testing) - data_hs.testing$x_attending_college
mse.lasso.coll <- mean(residuals.lasso.coll^2)
```

**Linear Models with theoretically important variables**
```{r}
data_hs.lm_training <- data_hs.training %>% 
  dplyr::select(c(
    average_class_size,
    x_economically_disadvantaged,
    x_english_language_learner,
    average_expenditures_per_pupil,
    x_females,
    average_salary,
    x_students_with_disabilities,
    average_in_district_expenditures_per_pupil,
    x_first_language_not_english,
    violent_crime,
    total_sat,
    x_graduated,
    x_attending_college
  )) %>% drop_na()

indep_vars.sat <- data_hs.lm_training %>% dplyr::select(-c(x_graduated, x_attending_college))
lm.sat <- lm(total_sat ~ ., data = indep_vars.sat)
summary(lm.sat)
residuals.lm.sat <- predict(lm.sat, data_hs.testing) - data_hs.testing$total_sat
mse.lm.sat <- mean(residuals.lm.sat^2)

indep_vars.grad <- data_hs.lm_training %>% dplyr::select(-c(total_sat, x_attending_college))
lm.grad <- lm(x_graduated ~ ., data = indep_vars.grad)
summary(lm.grad)
residuals.lm.grad <- predict(lm.grad, data_hs.testing) - data_hs.testing$x_graduated
mse.lm.grad <- mean(residuals.lm.grad^2)

indep_vars.coll <- data_hs.lm_training %>% dplyr::select(-c(x_graduated, total_sat))
lm.coll <- lm(x_attending_college ~ ., data = indep_vars.coll)
summary(lm.coll)
residuals.lm.coll <- predict(lm.coll, data_hs.testing) - data_hs.testing$x_attending_college
mse.lm.coll <- mean(residuals.lm.coll^2)
```
**Random Forest for SAT**
```{r}
set.seed(1)
rf.error.p.sat <- 1:19 # set up a vector of length 19
for (p in 1:19){ # repeat the following code inside { } 19 times 
fit.rf.sat <- randomForest(total_sat~., data_hs_sat, mtry=p, ntree=500) #plot(fit.rf, col= p, lwd = 3)
rf.error.p.sat[p] <- fit.rf.sat$mse[500]}
# collecting oob mse based on 250 trees

# rf.error.p.sat 
plot(1:19, rf.error.p.sat, pch=16,
main = "Testing errors of mtry with 250 trees", xlab="mtry",
ylab="OOB mse of mtry")
lines(1:19, rf.error.p.sat)


fit.rf.sat <- randomForest(total_sat~., data_hs_sat, mtry=19, ntree=500)
plot(fit.rf.sat, col="red", pch=16, type="p",
main="default plot, ")

residuals.sat.rf <- predict(fit.rf.sat, data_hs.testing) - data_hs.testing$total_sat
mse.residuals.sat.rf <- mean((residuals.sat.rf[!(is.na(residuals.sat.rf))])^2)

plot(x = (predict(fit.rf.sat, data_hs.testing)), y = data_hs.testing$total_sat)


```

**Random Forest for Grad Rate**
```{r}
set.seed(1)

rf.error.p.gradrate <- 1:19
for (p in 1:19){ # repeat the following code inside { } 19 times 
fit.rf.gradrate <- randomForest(x_graduated~., data_hs_gradrate, mtry=20, ntree=500) #plot(fit.rf, col= p, lwd = 3)
rf.error.p.gradrate[p] <- fit.rf.gradrate$mse[500] # collecting oob mse based on 250 trees
}
# rf.error.p.gradrate

plot(1:19, rf.error.p.gradrate, pch=16,
main = "Testing errors of mtry with 250 trees", xlab="mtry",
ylab="OOB mse of mtry")
lines(1:19, rf.error.p.gradrate)

fit.rf.gradrate <- randomForest(x_graduated~., data_hs_gradrate, mtry=7, ntree=500)
plot(fit.rf.gradrate, col="red", pch=16, type="p",
main="default plot, ")

residuals.gradrate.rf <- predict(fit.rf.gradrate, data_hs.testing) - data_hs.testing$x_graduated
mse.residuals.gradrate.rf <- mean((residuals.gradrate.rf[!(is.na(residuals.gradrate.rf))])^2)

plot(x = (predict(fit.rf.gradrate, data_hs.testing)), y = data_hs.testing$x_graduated)
```

**Random Forest for College Attendance Rate**
```{r}
set.seed(1)
rf.error.p.college <- 1:19
for (p in 1:19){ # repeat the following code inside { } 19 times 
fit.rf.college <- randomForest(x_attending_college~., data_hs_college, mtry=20, ntree=500) #plot(fit.rf, col= p, lwd = 3)
rf.error.p.college[p] <- fit.rf.college$mse[500] # collecting oob mse based on 250 trees
}
# rf.error.p.college

plot(1:19, rf.error.p.college, pch=16,
main = "Testing errors of mtry with 250 trees", xlab="mtry",
ylab="OOB mse of mtry")
lines(1:19, rf.error.p.college)

fit.rf.college <- randomForest(x_attending_college~., data_hs_college, mtry=6, ntree=500)
plot(fit.rf.college, col="red", pch=16, type="p",
main="default plot, ")

residuals.college.rf <- predict(fit.rf.college, data_hs.testing) - data_hs.testing$x_attending_college
mse.residuals.college.rf <- mean((residuals.college.rf[!(is.na(residuals.college.rf))])^2)

plot(x = (predict(fit.rf.college, data_hs.testing)), y = data_hs.testing$x_attending_college)

```

**Nueral Net**
```{r}
library(keras)

tensorflow::set_random_seed(1)

p <- dim(data_hs.training)[2]
model <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 16, activation = "relu", input_shape = c(p)) %>% 
  keras::layer_dense(units = 8, activation = "relu") %>%  
  keras::layer_dense(units = 2, activation = "softmax")
print(model)

library(keras)
```

